# -*- coding: utf-8 -*-
"""Canine_sex.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CACrl9vPu7-Kj77aLOD-OOtQdtvvGMme

# **Library and packages**

---



---
"""

import pandas as pd
import warnings
warnings.filterwarnings("ignore")
from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_predict, KFold
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import numpy as np
from sklearn import metrics
from sklearn.preprocessing import LabelBinarizer
import seaborn as sns
from sklearn.utils import resample
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from imblearn.under_sampling import RandomUnderSampler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import StratifiedKFold
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split


"""# **Dataset**"""

data = pd.read_excel('/content/2Tabela TC Medidas - v25_esmalte.xlsx')

data.columns

data.info()

"""# **Data preprocessing**"""

data = data.drop(columns=['Nº do paciente ','Data da imagem ', 'Data de nascimento ', 'Data da medição', 'Idade (anos:..:..)','Espessura esmalte e dentina mm','Dente analisado'])
data['Espessura média do esmalte'] = data[['Espessura esmalte 1 (ED1) mm', 'Espessura esmalte 2 (ED2) mm', 'Espessura esmalte 3 (ED3) mm']].mean(axis=1)
data.drop(['Espessura esmalte 1 (ED1) mm', 'Espessura esmalte 2 (ED2) mm', 'Espessura esmalte 3 (ED3) mm'], axis=1, inplace=True)

data.rename(columns={'Comprimento Total do Dente (T) - mm': 'Total Tooth Length - mm',
                     'Comprimento mésio-distal mm': 'Mesio-distal Length - mm',
                     'Espessura média do esmalte': 'Average Enamel Thickness'}, inplace=True)

data.head()

"""# **Multicollinearity analysis**"""

data2 = data.drop(columns=['Sexo'])
correlation_matrix = data2.corr()
colors = sns.color_palette("coolwarm", as_cmap=True)
plt.figure(figsize=(10, 8))
heatmap = sns.heatmap(correlation_matrix, annot=True, cmap=colors, fmt=".2f", linewidths=0.5, cbar_kws={'label': 'Correlation Coefficient'})
plt.title('Correlation Map among variables', fontsize=18)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14, rotation=0)  # Rotate labels on the y-axis for better readability
heatmap.set_xticklabels(['Total Tooth Length - mm', 'Mesio-Distal Length - mm', 'Average Enamel Thickness'], fontsize=14)
heatmap.set_yticklabels(['Total Tooth Length - mm', 'Mesio-Distal Length - mm', 'Average Enamel Thickness'], fontsize=14, rotation=0)
color_bar = plt.colorbar()
color_bar.ax.tick_params(labelsize=14)
plt.tight_layout()
plt.show()
plt.savefig('Figure 2.jpg', dpi=300, bbox_inches='tight')

"""# **Model building**"""

data['Sexo'].value_counts()

X = data.iloc[:,1:]
y = data.iloc[:,0]

scaler = StandardScaler()
X = scaler.fit_transform(X)

le = LabelEncoder()
y = le.fit_transform(y)

RANDOM_STATE = 42
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)

#SMOTE - oversampling (only train data)
oversample = SMOTE(random_state=RANDOM_STATE)
X_train, y_train = oversample.fit_resample(X_train, y_train)

#K-folds
fold = 10

"""#**DECISION TREE**"""

param_grid = {
    'criterion': ['gini', 'entropy'],
    'splitter': ['best', 'random'],
    'max_depth': [None, 5, 10, 15],
    # 'min_samples_split': [2, 5, 10],
    # 'min_samples_leaf': [1, 2, 4]
}
tree_clf = DecisionTreeClassifier(random_state=RANDOM_STATE)
grid_search = GridSearchCV(estimator=tree_clf, param_grid=param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)
print("Best Parameters:", grid_search.best_params_)
print("Best Score:", grid_search.best_score_)
best_tree_clf = grid_search.best_estimator_
best_tree_clf.fit(X_train, y_train)
y_pred_test_dt = best_tree_clf.predict(X_test)
conf_matrix = confusion_matrix(y_test, y_pred_test_dt)
accuracy_dt = accuracy_score(y_test, y_pred_test_dt)
report = classification_report(y_test, y_pred_test_dt)

print("Confusion Matrix (Test Data):\n", conf_matrix)
print("Accuracy:", accuracy_dt)
print("Classification Report (Test Data):\n", report)
kf_dt = KFold(n_splits=fold, shuffle=True, random_state=RANDOM_STATE)
y_pred_cv_dt = cross_val_predict(best_tree_clf, X_train, y_train, cv=kf_dt)
conf_matrix_cv = confusion_matrix(y_train, y_pred_cv_dt)
accuracy_cv_dt = accuracy_score(y_train, y_pred_cv_dt)
report_cv = classification_report(y_train, y_pred_cv_dt)

print("Confusion Matrix (Cross-Validation):\n", conf_matrix_cv)
print("Cross-Validation Accuracy:", accuracy_cv_dt)
print("Classification Report (Cross-Validation):\n", report_cv)

#Calculation of ROC Curve metrics and graph plotting (Test data and cross-validation)

def plot_roc_curve(fpr, tpr, auc_score, title='Receiver Operating Characteristic'):
    plt.figure(figsize=(8, 8))
    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(auc_score))
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(title)
    plt.legend(loc='lower right')
    plt.show()
y_prob_test_dt = best_tree_clf.predict_proba(X_test)[:, 1]
fpr_dt, tpr_dt, _ = roc_curve(y_test, y_prob_test_dt)
roc_auc_dt = auc(fpr_dt, tpr_dt)
plot_roc_curve(fpr_dt, tpr_dt, roc_auc_dt, title='ROC - Decision Tree - Test Data')
kf_dt = StratifiedKFold(n_splits=fold, shuffle=True, random_state=RANDOM_STATE)
y_prob_cv_dt = cross_val_predict(best_tree_clf, X_train, y_train, cv=kf_dt, method='predict_proba')[:, 1]
fpr_cv_dt, tpr_cv_dt, _ = roc_curve(y_train, y_prob_cv_dt)
roc_auc_cv_dt = auc(fpr_cv_dt, tpr_cv_dt)
plot_roc_curve(fpr_cv_dt, tpr_cv_dt, roc_auc_cv_dt, title='ROC - Decision Tree - Cross-Validation')

#FEATURE IMPORTANCE

X_2 = data.drop('Sexo', axis=1)
features_2 = []

for column in X_2.columns:
    features_2.append(column)

imp_features_dt2 = best_tree_clf.feature_importances_
df_imp_features_dt2 = pd.DataFrame({"features": features_2, "weights": imp_features_dt2})
df_imp_features_dt2_sorted = df_imp_features_dt2.sort_values(by='weights', ascending=True)
plt.figure(figsize=(10, 6))
colors = plt.cm.Blues(np.linspace(0.2, 1, len(df_imp_features_dt2_sorted)))
bars = plt.barh(df_imp_features_dt2_sorted['features'], df_imp_features_dt2_sorted['weights'], color=colors)
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.title('Feature Importance')

for bar in bars:
    plt.text(bar.get_width(), bar.get_y() + bar.get_height()/2, round(bar.get_width(), 4),
             va='center', ha='left', fontsize=10, color='white')
plt.gca().spines['top'].set_visible(False)
plt.gca().spines['right'].set_visible(False)
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.gca().set_facecolor('white')
plt.tight_layout()
plt.show()
plt.savefig('figimpDT.jpg', dpi=300, bbox_inches='tight')

"""**LOGISTIC REGRESSION**"""

param_grid = {
    'penalty': ['l1', 'l2'],
    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],
}

logreg_model = LogisticRegression(random_state=RANDOM_STATE)
grid_search = GridSearchCV(estimator=logreg_model, param_grid=param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)
print("Best Parameters:", grid_search.best_params_)
print("Best Score:", grid_search.best_score_)
best_logreg_model = grid_search.best_estimator_
best_logreg_model.fit(X_train, y_train)
y_pred_test_logreg = best_logreg_model.predict(X_test)
y_prob_test_logreg = best_logreg_model.predict_proba(X_test)[:, 1]

conf_matrix_logreg = confusion_matrix(y_test, y_pred_test_logreg)
accuracy_logreg = accuracy_score(y_test, y_pred_test_logreg)
report_logreg = classification_report(y_test, y_pred_test_logreg)

print("Confusion Matrix (Test Data):\n", conf_matrix_logreg)
print("Accuracy:", accuracy_logreg)
print("Classification Report (Test Data):\n", report_logreg)

kf_logreg = KFold(n_splits=fold, shuffle=True, random_state=RANDOM_STATE)
y_prob_cv_logreg = cross_val_predict(best_logreg_model, X_train, y_train, cv=kf_logreg, method='predict_proba')[:, 1]

y_pred_cv_logreg = cross_val_predict(best_logreg_model, X_train, y_train, cv=kf_logreg)
conf_matrix_cv_logreg = confusion_matrix(y_train, y_pred_cv_logreg)
accuracy_cv_logreg = accuracy_score(y_train, y_pred_cv_logreg)
report_cv_logreg = classification_report(y_train, y_pred_cv_logreg)

print("Confusion Matrix (Cross-Validation):\n", conf_matrix_cv_logreg)
print("Cross-Validation Accuracy:", accuracy_cv_logreg)
print("Classification Report (Cross-Validation):\n", report_cv_logreg)

###Calculation of ROC Curve metrics and graph plotting (Test data and cross-validation)

fpr_logreg, tpr_logreg, _ = roc_curve(y_test, y_prob_test_logreg)
roc_auc_logreg = auc(fpr_logreg, tpr_logreg)

plt.figure(figsize=(8, 8))
plt.plot(fpr_logreg, tpr_logreg, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc_logreg))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic - Test Data')
plt.legend(loc='lower right')
plt.show()
fpr_cv_logreg, tpr_cv_logreg, _ = roc_curve(y_train, y_prob_cv_logreg)
roc_auc_cv_logreg = auc(fpr_cv_logreg, tpr_cv_logreg)
plt.figure(figsize=(8, 8))
plt.plot(fpr_cv_logreg, tpr_cv_logreg, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc_cv_logreg))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic - Cross-Validation')
plt.legend(loc='lower right')
plt.show()

# FEATURE IMPORTANCE
imp_features_lr = best_logreg_model.coef_[0]
df_imp_features_lr = pd.DataFrame({"features": X_2.columns, "weights": np.abs(imp_features_lr)})
df_imp_features_lr_sorted = df_imp_features_lr.sort_values(by='weights', ascending=True)
plt.figure(figsize=(10, 6))
colors = plt.cm.Blues(np.linspace(0.2, 1, len(df_imp_features_lr_sorted)))
bars = plt.barh(df_imp_features_lr_sorted['features'], df_imp_features_lr_sorted['weights'], color=colors)
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.title('Feature Importance - Logistic Regression')

for bar in bars:
    plt.text(bar.get_width(), bar.get_y() + bar.get_height()/2, round(bar.get_width(), 4),
             va='center', ha='left', fontsize=10, color='white')

plt.gca().spines['top'].set_visible(False)
plt.gca().spines['right'].set_visible(False)

plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.gca().set_facecolor('white')
plt.tight_layout()
plt.savefig('figimpLR.jpg', dpi=300, bbox_inches='tight')
plt.show()

"""**KNN**"""

param_grid = {
    'n_neighbors': [3, 5, 7, 9],
    'weights': ['uniform', 'distance'],
    'p': [1, 2]  # 1 para distância de Manhattan, 2 para distância Euclidiana
}
knn_model = KNeighborsClassifier()
grid_search = GridSearchCV(estimator=knn_model, param_grid=param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)
print("Best Parameters:", grid_search.best_params_)
print("Best Score:", grid_search.best_score_)
best_knn_model = grid_search.best_estimator_
best_knn_model.fit(X_train, y_train)
y_pred_test_knn = best_knn_model.predict(X_test)
y_prob_test_knn = best_knn_model.predict_proba(X_test)[:, 1]
conf_matrix_knn = confusion_matrix(y_test, y_pred_test_knn)
accuracy_knn = accuracy_score(y_test, y_pred_test_knn)
report_knn = classification_report(y_test, y_pred_test_knn)

print("Confusion Matrix (Test Data):\n", conf_matrix_knn)
print("Accuracy:", accuracy_knn)
print("Classification Report (Test Data):\n", report_knn)

kf_knn = KFold(n_splits=fold, shuffle=True, random_state=RANDOM_STATE)
y_prob_cv_knn = cross_val_predict(best_knn_model, X_train, y_train, cv=kf_knn, method='predict_proba')[:, 1]

y_pred_cv_knn = cross_val_predict(best_knn_model, X_train, y_train, cv=kf_knn)
conf_matrix_cv_knn = confusion_matrix(y_train, y_pred_cv_knn)
accuracy_cv_knn = accuracy_score(y_train, y_pred_cv_knn)
report_cv_knn = classification_report(y_train, y_pred_cv_knn)

print("Confusion Matrix (Cross-Validation):\n", conf_matrix_cv_knn)
print("Cross-Validation Accuracy:", accuracy_cv_knn)
print("Classification Report (Cross-Validation):\n", report_cv_knn)

###Calculation of ROC Curve metrics and graph plotting (Test data and cross-validation)
fpr_knn, tpr_knn, _ = roc_curve(y_test, y_prob_test_knn)
roc_auc_knn = auc(fpr_knn, tpr_knn)

plt.figure(figsize=(8, 8))
plt.plot(fpr_knn, tpr_knn, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc_knn))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic - Test Data')
plt.legend(loc='lower right')
plt.show()

fpr_cv_knn, tpr_cv_knn, _ = roc_curve(y_train, y_prob_cv_knn)
roc_auc_cv_knn = auc(fpr_cv_knn, tpr_cv_knn)

plt.figure(figsize=(8, 8))
plt.plot(fpr_cv_knn, tpr_cv_knn, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc_cv_knn))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic - Cross-Validation')
plt.legend(loc='lower right')
plt.show()

"""**Gradient Boosting Classifier**"""

param_grid = {
    'n_estimators': [50, 100, 200],
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 5, 7],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

gb_model = GradientBoostingClassifier(random_state=RANDOM_STATE)
grid_search = GridSearchCV(estimator=gb_model, param_grid=param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)
print("Best Parameters:", grid_search.best_params_)
print("Best Score:", grid_search.best_score_)
best_gb_model = grid_search.best_estimator_
best_gb_model.fit(X_train, y_train)
y_pred_test_gb = best_gb_model.predict(X_test)
y_prob_test_gb = best_gb_model.predict_proba(X_test)[:, 1]
conf_matrix_gb = confusion_matrix(y_test, y_pred_test_gb)
accuracy_gb = accuracy_score(y_test, y_pred_test_gb)
report_gb = classification_report(y_test, y_pred_test_gb)

print("Confusion Matrix (Test Data):\n", conf_matrix_gb)
print("Accuracy:", accuracy_gb)
print("Classification Report (Test Data):\n", report_gb)

kf_gb = KFold(n_splits=fold, shuffle=True, random_state=RANDOM_STATE)
y_prob_cv_gb = cross_val_predict(best_gb_model, X_train, y_train, cv=kf_gb, method='predict_proba')[:, 1]

y_pred_cv_gb = cross_val_predict(best_gb_model, X_train, y_train, cv=kf_gb)
conf_matrix_cv_gb = confusion_matrix(y_train, y_pred_cv_gb)
accuracy_cv_gb = accuracy_score(y_train, y_pred_cv_gb)
report_cv_gb = classification_report(y_train, y_pred_cv_gb)

print("Confusion Matrix (Cross-Validation):\n", conf_matrix_cv_gb)
print("Cross-Validation Accuracy:", accuracy_cv_gb)
print("Classification Report (Cross-Validation):\n", report_cv_gb)

###Calculation of ROC Curve metrics and graph plotting (Test data and cross-validation)
fpr_gb, tpr_gb, _ = roc_curve(y_test, y_prob_test_gb)
roc_auc_gb = auc(fpr_gb, tpr_gb)

plt.figure(figsize=(8, 8))
plt.plot(fpr_gb, tpr_gb, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc_gb))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic - Test Data')
plt.legend(loc='lower right')
plt.show()

fpr_cv_gb, tpr_cv_gb, _ = roc_curve(y_train, y_prob_cv_gb)
roc_auc_cv_gb = auc(fpr_cv_gb, tpr_cv_gb)

plt.figure(figsize=(8, 8))
plt.plot(fpr_cv_gb, tpr_cv_gb, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc_cv_gb))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic - Cross-Validation')
plt.legend(loc='lower right')
plt.show()

##FEATURE IMPORTANCE

imp_features_gb = best_gb_model.feature_importances_
df_imp_features_gb = pd.DataFrame({"features": X_2.columns, "weights": np.abs(imp_features_gb)})
df_imp_features_gb_sorted = df_imp_features_gb.sort_values(by='weights', ascending=True)
plt.figure(figsize=(10, 6))
colors = plt.cm.Blues(np.linspace(0.2, 1, len(df_imp_features_gb_sorted)))
bars = plt.barh(df_imp_features_gb_sorted['features'], df_imp_features_gb_sorted['weights'], color=colors)
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.title('Feature Importance (Gradient Boosting)')
for bar in bars:
    plt.text(bar.get_width(), bar.get_y() + bar.get_height()/2, round(bar.get_width(), 4),
             va='center', ha='left', fontsize=10, color='white')

plt.gca().spines['top'].set_visible(False)
plt.gca().spines['right'].set_visible(False)

plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.gca().set_facecolor('white')

plt.tight_layout()

plt.savefig('figimpGB.jpg', dpi=300, bbox_inches='tight')

plt.show()

"""**RANDOM FOREST CLASSIFIER**"""

param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 5, 10, 15],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

rf_model = RandomForestClassifier(random_state=RANDOM_STATE)
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)
print("Best Parameters:", grid_search.best_params_)
print("Best Score:", grid_search.best_score_)
best_rf_model = grid_search.best_estimator_
best_rf_model.fit(X_train, y_train)
y_pred_test_rf = best_rf_model.predict(X_test)
y_prob_test_rf = best_rf_model.predict_proba(X_test)[:, 1]
conf_matrix_rf = confusion_matrix(y_test, y_pred_test_rf)
accuracy_rf = accuracy_score(y_test, y_pred_test_rf)
report_rf = classification_report(y_test, y_pred_test_rf)

print("Confusion Matrix (Test Data):\n", conf_matrix_rf)
print("Accuracy:", accuracy_rf)
print("Classification Report (Test Data):\n", report_rf)

kf_rf = KFold(n_splits=fold, shuffle=True, random_state=RANDOM_STATE)
y_prob_cv_rf = cross_val_predict(best_rf_model, X_train, y_train, cv=kf_rf, method='predict_proba')[:, 1]

y_pred_cv_rf = cross_val_predict(best_rf_model, X_train, y_train, cv=kf_rf)
conf_matrix_cv_rf = confusion_matrix(y_train, y_pred_cv_rf)
accuracy_cv_rf = accuracy_score(y_train, y_pred_cv_rf)
report_cv_rf = classification_report(y_train, y_pred_cv_rf)

print("Confusion Matrix (Cross-Validation):\n", conf_matrix_cv_rf)
print("Cross-Validation Accuracy:", accuracy_cv_rf)
print("Classification Report (Cross-Validation):\n", report_cv_rf)

###Calculation of ROC Curve metrics and graph plotting (Test data and cross-validation)

fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_test_rf)
roc_auc_rf = auc(fpr_rf, tpr_rf)

plt.figure(figsize=(8, 8))
plt.plot(fpr_rf, tpr_rf, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc_rf))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic - Test Data')
plt.legend(loc='lower right')
plt.show()
fpr_cv_rf, tpr_cv_rf, _ = roc_curve(y_train, y_prob_cv_rf)
roc_auc_cv_rf = auc(fpr_cv_rf, tpr_cv_rf)

plt.figure(figsize=(8, 8))
plt.plot(fpr_cv_rf, tpr_cv_rf, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc_cv_rf))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic - Cross-Validation')
plt.legend(loc='lower right')
plt.show()

##FEATURE IMPORTANCE

imp_features_rf = best_rf_model.feature_importances_
df_imp_features_rf = pd.DataFrame({"features": X_2.columns, "weights": np.abs(imp_features_rf)})
df_imp_features_rf_sorted = df_imp_features_rf.sort_values(by='weights', ascending=True)
plt.figure(figsize=(10, 6))
colors = plt.cm.Blues(np.linspace(0.2, 1, len(df_imp_features_rf_sorted)))
bars = plt.barh(df_imp_features_rf_sorted['features'], df_imp_features_rf_sorted['weights'], color=colors)
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.title('Feature Importance (Random Forest)')
for bar in bars:
    plt.text(bar.get_width(), bar.get_y() + bar.get_height()/2, round(bar.get_width(), 4),
             va='center', ha='left', fontsize=10, color='white')
plt.gca().spines['top'].set_visible(False)
plt.gca().spines['right'].set_visible(False)
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.gca().set_facecolor('white')
plt.tight_layout()
plt.savefig('figimpRF.jpg', dpi=300, bbox_inches='tight')

plt.show()

"""#**SVM**"""

param_grid = {
    'C': [0.001, 0.1,0.5, 0.9, 1.5, 2.3,23, 50, 100],
    'kernel': ['linear','rbf'],
    'gamma': ['auto','scale']
}
svc_model = SVC(random_state=RANDOM_STATE, probability=True)
grid_search = GridSearchCV(estimator=svc_model, param_grid=param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)
print("Best Parameters:", grid_search.best_params_)
print("Best Score:", grid_search.best_score_)
best_svc_model = grid_search.best_estimator_
best_svc_model.fit(X_train, y_train)
y_pred_test_svc = best_svc_model.predict(X_test)
y_prob_test_svc = best_svc_model.predict_proba(X_test)[:, 1]
conf_matrix_svc = confusion_matrix(y_test, y_pred_test_svc)
accuracy_svc = accuracy_score(y_test, y_pred_test_svc)
report_svc = classification_report(y_test, y_pred_test_svc)

print("Confusion Matrix (Test Data):\n", conf_matrix_svc)
print("Accuracy:", accuracy_svc)
print("Classification Report (Test Data):\n", report_svc)
kf_svc = KFold(n_splits=fold, shuffle=True, random_state=RANDOM_STATE)
y_prob_cv_svc = cross_val_predict(best_svc_model, X_train, y_train, cv=kf_svc, method='predict_proba')[:, 1]

y_pred_cv_svc = cross_val_predict(best_svc_model, X_train, y_train, cv=kf_svc)
conf_matrix_cv_svc = confusion_matrix(y_train, y_pred_cv_svc)
accuracy_cv_svc = accuracy_score(y_train, y_pred_cv_svc)
report_cv_svc = classification_report(y_train, y_pred_cv_svc)

print("Confusion Matrix (Cross-Validation):\n", conf_matrix_cv_svc)
print("Cross-Validation Accuracy:", accuracy_cv_svc)
print("Classification Report (Cross-Validation):\n", report_cv_svc)

###Calculation of ROC Curve metrics and graph plotting (Test data and cross-validation)
fpr_svc, tpr_svc, _ = roc_curve(y_test, y_prob_test_svc)
roc_auc_svc = auc(fpr_svc, tpr_svc)

plt.figure(figsize=(8, 8))
plt.plot(fpr_svc, tpr_svc, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc_svc))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic - Test Data')
plt.legend(loc='lower right')
plt.show()
# Plotar a curva ROC para a validação cruzada
fpr_cv_svc, tpr_cv_svc, _ = roc_curve(y_train, y_prob_cv_svc)
roc_auc_cv_svc = auc(fpr_cv_svc, tpr_cv_svc)

plt.figure(figsize=(8, 8))
plt.plot(fpr_cv_svc, tpr_cv_svc, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc_cv_svc))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic - Cross-Validation')
plt.legend(loc='lower right')
plt.show()

"""**MLP Classifier**"""

param_grid = {
    'hidden_layer_sizes': [10, 100, 1000],
    'alpha': [ 0.01, 0.1, 1.0],
    'learning_rate_init': [0.01, 0.1, 1],
    'activation': ['relu', 'logistic', 'tanh'],
    'max_iter': [50, 100, 1000],
    'solver': ['lbfgs', 'sgd', 'adam']
}

mlp_model = MLPClassifier(random_state=RANDOM_STATE)

grid_search = GridSearchCV(estimator=mlp_model, param_grid=param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)
print("Best Parameters:", grid_search.best_params_)
print("Best Score:", grid_search.best_score_)
best_mlp_model = grid_search.best_estimator_
best_mlp_model.fit(X_train, y_train)
y_pred_test_mlp = best_mlp_model.predict(X_test)
y_prob_test_mlp = best_mlp_model.predict_proba(X_test)[:, 1]
conf_matrix_mlp = confusion_matrix(y_test, y_pred_test_mlp)
accuracy_mlp = accuracy_score(y_test, y_pred_test_mlp)
report_mlp = classification_report(y_test, y_pred_test_mlp)

print("Confusion Matrix (Test Data):\n", conf_matrix_mlp)
print("Accuracy:", accuracy_mlp)
print("Classification Report (Test Data):\n", report_mlp)

kf_mlp = KFold(n_splits=fold, shuffle=True, random_state=RANDOM_STATE)
y_prob_cv_mlp = cross_val_predict(best_mlp_model, X_train, y_train, cv=kf_mlp, method='predict_proba')[:, 1]

y_pred_cv_mlp = cross_val_predict(best_mlp_model, X_train, y_train, cv=kf_mlp)
conf_matrix_cv_mlp = confusion_matrix(y_train, y_pred_cv_mlp)
accuracy_cv_mlp = accuracy_score(y_train, y_pred_cv_mlp)
report_cv_mlp = classification_report(y_train, y_pred_cv_mlp)

print("Confusion Matrix (Cross-Validation):\n", conf_matrix_cv_mlp)
print("Cross-Validation Accuracy:", accuracy_cv_mlp)
print("Classification Report (Cross-Validation):\n", report_cv_mlp)

###Calculation of ROC Curve metrics and graph plotting (Test data and cross-validation)
fpr_mlp, tpr_mlp, _ = roc_curve(y_test, y_prob_test_mlp)
roc_auc_mlp = auc(fpr_mlp, tpr_mlp)
plt.figure(figsize=(8, 8))
plt.plot(fpr_mlp, tpr_mlp, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc_mlp))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic - Test Data')
plt.legend(loc='lower right')
plt.show()

fpr_cv_mlp, tpr_cv_mlp, _ = roc_curve(y_train, y_prob_cv_mlp)
roc_auc_cv_mlp = auc(fpr_cv_mlp, tpr_cv_mlp)

plt.figure(figsize=(8, 8))
plt.plot(fpr_cv_mlp, tpr_cv_mlp, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc_cv_mlp))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic - Cross-Validation')
plt.legend(loc='lower right')
plt.show()

"""#**PLOTS**"""

plt.style.use('seaborn-whitegrid')
fig, axs = plt.subplots(1, 2, figsize=(20, 8))  # Criando subplots com 1 linha e 2 colunas

axs[0].plot(fpr_svc, tpr_svc, color='green', lw=2, label='Support Vector Machine (AUC = %0.2f)' % roc_auc_svc)
axs[0].plot(fpr_mlp, tpr_mlp, color='purple', lw=2, label='Multilayer Perceptron (AUC = %0.2f)' % roc_auc_mlp)
axs[0].plot(fpr_rf, tpr_rf, color='deeppink', lw=2, label='Random Forest (AUC = %0.2f)' % roc_auc_rf)
axs[0].plot(fpr_logreg, tpr_logreg, color='red', lw=2, label='Logistic Regression (AUC = %0.2f)' % roc_auc_logreg)
axs[0].plot(fpr_dt, tpr_dt, color='gray', lw=2, label='Decision Tree (AUC = %0.2f)' % roc_auc_dt)
axs[0].plot(fpr_gb, tpr_gb, color='orange', lw=2, label='Gradient Boosting (AUC = %0.2f)' % roc_auc_gb)
axs[0].plot(fpr_knn, tpr_knn, color='blue', lw=2, label='K Nearest Neighbors (AUC = %0.2f)' % roc_auc_knn)
axs[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
axs[0].set_xlim([0.0, 1.0])
axs[0].set_ylim([0.0, 1.05])
axs[0].set_xlabel('False Positive Rate')
axs[0].set_ylabel('True Positive Rate')
axs[0].set_title('Receiver Operating Characteristic (ROC) Curve')
axs[0].legend(loc="lower right")
axs[1].plot(fpr_cv_svc, tpr_cv_svc, color='green', lw=2, label='Support Vector Machine (AUC = %0.2f)' % roc_auc_cv_svc)
axs[1].plot(fpr_cv_mlp, tpr_cv_mlp, color='purple', lw=2, label='Multilayer Perceptron (AUC = %0.2f)' % roc_auc_cv_mlp)
axs[1].plot(fpr_cv_rf, tpr_cv_rf, color='deeppink', lw=2, label='Random Forest (AUC = %0.2f)' % roc_auc_cv_rf)
axs[1].plot(fpr_cv_logreg, tpr_cv_logreg, color='red', lw=2, label='Logistic Regression (AUC = %0.2f)' % roc_auc_cv_logreg)
axs[1].plot(fpr_cv_knn, tpr_cv_knn, color='blue', lw=2, label='K Nearest Neighbors (AUC = %0.2f)' % roc_auc_cv_knn)
axs[1].plot(fpr_cv_gb, tpr_cv_gb, color='orange', lw=2, label='Gradient Boosting (AUC = %0.2f)' % roc_auc_cv_gb)
axs[1].plot(fpr_cv_dt, tpr_cv_dt, color='gray', lw=2, label='Decision Tree (AUC = %0.2f)' % roc_auc_cv_dt)
axs[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
axs[1].set_xlim([0.0, 1.0])
axs[1].set_ylim([0.0, 1.05])
axs[1].set_xlabel('False Positive Rate')
axs[1].set_ylabel('True Positive Rate')
axs[1].set_title('Receiver Operating Characteristic (ROC) Curve')
axs[1].legend(loc="lower right")

plt.show()

imp_features_dt = best_tree_clf.feature_importances_
df_imp_features_dt = pd.DataFrame({"Features": X_2.columns, "Importance": np.abs(imp_features_dt)})
df_imp_features_dt_sorted = df_imp_features_dt.sort_values(by='Importance', ascending=True)
imp_features_gb = best_gb_model.feature_importances_
df_imp_features_gb = pd.DataFrame({"Features": X_2.columns, "Importance": np.abs(imp_features_gb)})
df_imp_features_gb_sorted = df_imp_features_gb.sort_values(by='Importance', ascending=True)
imp_features_lr = best_logreg_model.coef_[0]
df_imp_features_lr = pd.DataFrame({"Features": X_2.columns, "Importance": np.abs(imp_features_lr)})
df_imp_features_lr_sorted = df_imp_features_lr.sort_values(by='Importance', ascending=True)
imp_features_rf = best_rf_model.feature_importances_
df_imp_features_rf = pd.DataFrame({"Features": X_2.columns, "Importance": np.abs(imp_features_rf)})
df_imp_features_rf_sorted = df_imp_features_rf.sort_values(by='Importance', ascending=True)

fig, axs = plt.subplots(2, 2, figsize=(12, 10))
fig.suptitle('Feature Importance Comparison', fontsize=16)
colors_dt = plt.cm.Blues(np.linspace(0.2, 1, len(df_imp_features_dt_sorted)))
bars_dt = axs[0, 0].barh(df_imp_features_dt_sorted['Features'], df_imp_features_dt_sorted['Importance'], color=colors_dt)
axs[0, 0].set_title('Decision Tree')
colors_gb = plt.cm.Blues(np.linspace(0.2, 1, len(df_imp_features_gb_sorted)))
bars_gb = axs[0, 1].barh(df_imp_features_gb_sorted['Features'], df_imp_features_gb_sorted['Importance'], color=colors_gb)
axs[0, 1].set_title('Gradient Boosting')
axs[0, 1].grid(axis='x', linestyle='--', alpha=0.7)  # Adiciona grade ao subplot de Gradient Boosting
colors_lr = plt.cm.Blues(np.linspace(0.2, 1, len(df_imp_features_lr_sorted)))
bars_lr = axs[1, 0].barh(df_imp_features_lr_sorted['Features'], df_imp_features_lr_sorted['Importance'], color=colors_lr)
axs[1, 0].set_title('Logistic Regression')
colors_rf = plt.cm.Blues(np.linspace(0.2, 1, len(df_imp_features_rf_sorted)))
bars_rf = axs[1, 1].barh(df_imp_features_rf_sorted['Features'], df_imp_features_rf_sorted['Importance'], color=colors_rf)
axs[1, 1].set_title('Random Forest')
axs[1, 1].grid(axis='x', linestyle='--', alpha=0.7)  # Adiciona grade ao subplot de Random Forest
for bars, ax in zip([bars_dt, bars_gb, bars_lr, bars_rf], axs.flat):
    for bar in bars:
        ax.text(bar.get_width(), bar.get_y() + bar.get_height()/2, round(bar.get_width(), 4),
                va='center', ha='left', fontsize=8, color='white')
for ax in axs.flat:
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
for ax in axs[:, 0]:
    ax.grid(axis='x', linestyle='--', alpha=0.7)
for ax in axs.flat:
    ax.set_facecolor('white')
for ax in axs.flat:
    ax.set_xlabel('Importance')
    ax.set_ylabel('Feature')
plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.savefig('figimp_comparison.jpg', dpi=300, bbox_inches='tight')

plt.show()

